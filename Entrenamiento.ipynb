{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Entrenamiento.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFBY92w-O-hb"
      },
      "source": [
        "### Notebook que contiene los pasos para entrenar a un modelo de Mask R-CNN haciendo uso de un entrenamiento por capas y de la base de datos de sombras conocida como SBU-SHADOWS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGHPGgVSECGl"
      },
      "source": [
        "#Install needed packages (see requirements.txt in github repository)\n",
        "!pip install numpy\n",
        "!pip install \"scipy==1.4.1\"\n",
        "!pip install Pillow\n",
        "!pip install cython\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip uninstall keras-nightly\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.15.0\n",
        "!pip install keras==2.0.8\n",
        "!pip install opencv-python\n",
        "!pip uninstall h5py\n",
        "!pip install h5py==2.10.0\n",
        "!pip install imgaug\n",
        "#Download model\n",
        "!git clone https://github.com/nasca37/Mask_RCNN.git\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4feEQWa1Jb1I"
      },
      "source": [
        "%cd Mask_RCNN/\n",
        "\n",
        "#Download pre-trained weights \n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoiZk551EQcp"
      },
      "source": [
        "%cd Mask_RCNN/\n",
        "DATASET = 0\n",
        "\n",
        "!wget https://www.dropbox.com/s/660s0vgyk83aek9/Img.zip\n",
        "#!wget https://www.dropbox.com/s/w1henmfcu47a3cj/Mask.zip\n",
        "#!wget https://www.dropbox.com/s/zz5u3kh3q4xremn/MaskTrain.zip\n",
        "!wget https://www.dropbox.com/s/52ux32n0yu5xaq0/ImgTrain.zip\n",
        "\n",
        "!wget https://www.dropbox.com/s/yes1a53053zi6pv/Maskjson.zip\n",
        "!wget https://www.dropbox.com/s/brkhhd31cytt7z3/MaskTrainjson.zip\n",
        "\n",
        "!unzip Img.zip\n",
        "#!unzip Mask.zip\n",
        "!unzip Maskjson.zip \n",
        "!unzip ImgTrain.zip\n",
        "#!unzip MaskTrain.zip\n",
        "!unzip MaskTrainjson.zip  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s402-RTwL5oS"
      },
      "source": [
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from matplotlib import pyplot\n",
        "from csv import reader\n",
        "import json\n",
        "import numpy as np\n",
        "import ntpath\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE9mhSZgMAg8",
        "outputId": "35bf5c22-89a1-4a91-ef3b-cea48fe22fa7"
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"./\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.utils import extract_bboxes\n",
        "\n",
        "\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "DATASET_DIR_TEST=os.path.join(ROOT_DIR, \"Img\")\n",
        "#DATASET_MASK_TEST=os.path.join(ROOT_DIR, \"Mask\")\n",
        "DATASET_MASK_TEST=os.path.join(ROOT_DIR, \"Maskjson\")\n",
        "DATASET_DIR_TRAIN=os.path.join(ROOT_DIR, \"ImgTrain\")\n",
        "#DATASET_MASK_TRAIN=os.path.join(ROOT_DIR, \"MaskTrain\")\n",
        "DATASET_MASK_TRAIN=os.path.join(ROOT_DIR, \"MaskTrainjson\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft-gumtIMhlT"
      },
      "source": [
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "\n",
        "class ShadowsConfig(Config):\n",
        "    \"\"\"Configuration for training on the   dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"Shadows\"\n",
        "    \n",
        "    # A GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "#    IMAGES_PER_GPU = 2\n",
        "    IMAGES_PER_GPU = 2\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + shadow\n",
        "    \n",
        "    # Number of training steps per epoch\n",
        "    #STEPS_PER_EPOCH = 200\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "    MINI_MASK_SHAPE = (128, 128)\n",
        "    MASK_SHAPE = [56, 56]\n",
        "    LOSS_WEIGHTS = {\n",
        "      \"rpn_class_loss\":1.2,\n",
        "      \"rpn_bbox_loss\": 0.7,\n",
        "      \"mrcnn_class_loss\": 1.,\n",
        "      \"mrcnn_bbox_loss\": 0.7,\n",
        "      \"mrcnn_mask_loss\": 1.2\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttLGacWvNx3V"
      },
      "source": [
        "###############\n",
        "# Define model\n",
        "###############\n",
        "\n",
        "# define the model\n",
        "config = ShadowsConfig()\n",
        "model = MaskRCNN(mode='training', model_dir=DEFAULT_LOGS_DIR, config=config)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKNOvB7MN7JK"
      },
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import skimage\n",
        "import re\n",
        "class ShadowDataset(Dataset):\n",
        "\n",
        "    def load_shadow(self, isTrain = True):\n",
        "        \"\"\"Load a subset of the nuclei dataset.\n",
        "\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. Either the name of the sub-directory,\n",
        "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
        "                * train: stage1_train excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset nucleus, and the class nucleus\n",
        "        self.add_class(\"shadow\", 1, \"shadow\")\n",
        "        if isTrain:\n",
        "          dataset_dir = DATASET_DIR_TRAIN\n",
        "        else:\n",
        "          dataset_dir = DATASET_DIR_TEST\n",
        "\n",
        "        # Get image ids from directory names\n",
        "        image_ids = next(os.walk(dataset_dir))[2]\n",
        "        p = 1\n",
        "\n",
        "        n=len(image_ids)\n",
        "        all_indices=np.arange(n)\n",
        "        ntrain=int(p*n)\n",
        "        np.random.seed(100) #run this line before np.random.choice to choose always the same sequence of values\n",
        "        fimage_ids=np.random.choice(n, ntrain, replace=False)\n",
        "        \n",
        "        # Add images\n",
        "        for image_id in fimage_ids:\n",
        "            self.add_image(\n",
        "                \"shadow\",\n",
        "                image_id=image_ids[image_id],\n",
        "                path=os.path.join(dataset_dir, image_ids[image_id]))\n",
        "\n",
        "        \n",
        "\n",
        "    def load_mask(self, image_id,isTrain = True):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        id = re.findall(r'\\d+', info['id'])[0]\n",
        "        # Get mask directory from image path\n",
        "        if isTrain == False:\n",
        "          #mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"Mask/mask ({}).json\".format(id))\n",
        "          mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"Maskjson/mask ({}).json\".format(id))\n",
        "        else:\n",
        "          #mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"MaskTrain/mask ({}).json\".format(id))\n",
        "          mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"MaskTrainjson/mask ({}).json\".format(id))\n",
        "          \n",
        "        # Read mask info from .json file\n",
        "        datashadows = json.load(open(mask_dir))\n",
        "        # create one array for all masks, each on a different channel\n",
        "        mask = np.zeros([datashadows[\"height\"], datashadows[\"width\"], len(datashadows[\"regions\"])],\n",
        "                        dtype=np.uint8)\n",
        "             \n",
        "        for i, p in enumerate(datashadows[\"regions\"]):\n",
        "            mask[p['y'], p['x'], i] = 1\n",
        "        \n",
        "        \n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID, we return an array of ones\n",
        "        \n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"shadow\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDcl7wxpCFyK",
        "outputId": "db8ab50d-5ac8-4abd-dbee-5dbb76da12fb"
      },
      "source": [
        "###############\n",
        "# Check dataset\n",
        "###############\n",
        "\n",
        "# train set\n",
        "train_set = ShadowDataset()\n",
        "train_set.load_shadow( isTrain=True)\n",
        "train_set.prepare()\n",
        "\n",
        "#print info\n",
        "# enumerate all images in the dataset\n",
        "print(train_set.image_ids)\n",
        "for image_id in train_set.image_ids:\n",
        "\t# load image info\n",
        "\tinfo = train_set.image_info[image_id]\n",
        "\t# display on the console\n",
        "#\tprint(info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    1    2 ... 1631 1632 1633]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG2rmwWmFIz5"
      },
      "source": [
        "#display masks\n",
        "# load an image\n",
        "image_id = 45\n",
        "image = train_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "# load image mask\n",
        "mask, class_ids = train_set.load_mask(image_id,True)\n",
        "print(mask.shape)\n",
        "# plot image\n",
        "pyplot.imshow(image)\n",
        "# plot mask\n",
        "pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jiMgNHpSd_m"
      },
      "source": [
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\timage = train_set.load_image(i)\n",
        "\tpyplot.imshow(image)\n",
        "\t# plot all masks\n",
        "\tmask, _ = train_set.load_mask(i)\n",
        "\tfor j in range(mask.shape[2]):\n",
        "\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4wql81_SjRB"
      },
      "source": [
        "#display bounding boxes\n",
        "# define image id\n",
        "image_id = 1\n",
        "# load the image\n",
        "image = train_set.load_image(image_id)\n",
        "# load the masks and the class ids\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "# extract bounding boxes from the masks\n",
        "bbox = extract_bboxes(mask)\n",
        "# display image with masks and bounding boxes\n",
        "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MEwFkWRSpdx"
      },
      "source": [
        "###################################################\n",
        "#Draw ground truth masks on images from datasets \n",
        "###################################################\n",
        "# from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "\n",
        "from mrcnn import visualize\n",
        "\n",
        "# Training dataset.\n",
        "dataset_train = ShadowDataset()\n",
        "dataset_train.load_shadow( isTrain=True)\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = ShadowDataset()\n",
        "dataset_val.load_shadow( isTrain=False)\n",
        "dataset_val.prepare()\n",
        "\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4hqW2lxTDXR"
      },
      "source": [
        "# Test on a random image\n",
        "from mrcnn.model import log\n",
        "\n",
        "class InferenceConfig(ShadowsConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "image_id = np.random.choice(dataset_val.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_val, inference_config, \n",
        "                           image_id, use_mini_mask=False)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "\n",
        "#visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        " #                           dataset_train.class_names, figsize=(8, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QGf3wTGOxDI"
      },
      "source": [
        "### Entrenamiento por capas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UGw7SfbTSAA"
      },
      "source": [
        "###############\n",
        "# Train\n",
        "###############\n",
        "from imgaug import augmenters as iaa\n",
        "# Training dataset.\n",
        "dataset_train = ShadowDataset()\n",
        "dataset_train.load_shadow(isTrain=True)\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = ShadowDataset()\n",
        "dataset_val.load_shadow( isTrain=False)\n",
        "dataset_val.prepare()\n",
        "\n",
        "\n",
        "# train weights (output layers or 'heads')\n",
        "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=60, layers='heads')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4TCBT_l7pno"
      },
      "source": [
        "###############\n",
        "# Define model\n",
        "###############\n",
        "\n",
        "# define the model\n",
        "config2 = ShadowsConfig()\n",
        "logs = os.path.join(DEFAULT_LOGS_DIR,\"2\")\n",
        "model2 = MaskRCNN(mode='training', model_dir=logs, config=config2)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "LEARNED_WEIGHTS_PATH = os.path.join(DEFAULT_LOGS_DIR, \"shadows20210315T1237/mask_rcnn_shadows_0059.h5\")\n",
        "model2.load_weights(LEARNED_WEIGHTS_PATH, by_name=True)\n",
        "\n",
        "model2.train(dataset_train, dataset_val, learning_rate=config2.LEARNING_RATE/2, epochs=90, layers='3+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbErx8qS2DgO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmJcUhfZQ7VH"
      },
      "source": [
        "###############\n",
        "# Define model\n",
        "###############\n",
        "\n",
        "# define the model\n",
        "config3 = ShadowsConfig()\n",
        "logs = os.path.join(DEFAULT_LOGS_DIR,\"3\")\n",
        "model3 = MaskRCNN(mode='training', model_dir=logs, config=config2)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "LEARNED_WEIGHTS_PATH = os.path.join(DEFAULT_LOGS_DIR, \"2/shadows20210127T1027/mask_rcnn_shadows_0089.h5\")\n",
        "model3.load_weights(LEARNED_WEIGHTS_PATH, by_name=True)\n",
        "\n",
        "model3.train(dataset_train, dataset_val, learning_rate=config2.LEARNING_RATE*4, epochs=120, layers='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqSHptQs4tEq",
        "outputId": "eca7ff0c-dda0-433a-ced1-7ece5ce5528d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee6yFlJZ40Bb"
      },
      "source": [
        "model_save_name = 'classifierMaskRcnn(soloHead60).pt'\n",
        "path = F\"/content/drive/My Drive/{model_save_name}\" \n",
        "model.keras_model.save_weights(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JQM-pj7vU6C"
      },
      "source": [
        "def id_image(name):\n",
        "  finalpath = \"/content/Mask_RCNN/ImgTrain/\" + name\n",
        "  for id in train_set.image_ids:\n",
        "    path = train_set.image_reference(id)\n",
        "    if path == finalpath:\n",
        "      return id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGGphxlh4OeH"
      },
      "source": [
        "def id_image_test(name):\n",
        "  finalpath = \"/content/Mask_RCNN/Img/\" + name\n",
        "  for id in test_set.image_ids:\n",
        "    path = test_set.image_reference(id)\n",
        "    if path == finalpath:\n",
        "      return id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UzWStN-Ot2R"
      },
      "source": [
        "### ValidaciÃ³n de los resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdjwAYOGTjsh",
        "outputId": "ec17ed14-56d4-4257-e8ff-edc631577dc9"
      },
      "source": [
        "###################################\n",
        "#Evaluation of the trained model\n",
        "###################################\n",
        "\n",
        "# evaluate the mask rcnn model on the facesFDDB dataset\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "import math\n",
        "\n",
        "# define the prediction configuration\n",
        "class PredictionConfig(Config):\n",
        "    # define the name of the configuration\n",
        "    NAME = \"shadow\"\n",
        "    # number of classes (background + eye + mouth)\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    # simplify GPU config\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "# calculate the mAP for a model on a given dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tif not math.isnan(AP):\n",
        "\t\t    APs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP\n",
        "\n",
        "# load the train dataset\n",
        "train_set = ShadowDataset()\n",
        "train_set.load_shadow(isTrain=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# load the test dataset\n",
        "test_set = ShadowDataset()\n",
        "test_set.load_shadow(isTrain=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "\n",
        "# create config\n",
        "cfg = PredictionConfig()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir=DEFAULT_LOGS_DIR, config=cfg)\n",
        "# load model weights\n",
        "LEARNED_WEIGHTS_PATH = os.path.join(logs, \"shadows20210626T0839/mask_rcnn_shadows_0119.h5\")\n",
        "model.load_weights(LEARNED_WEIGHTS_PATH, by_name=True)\n",
        "\n",
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "\n",
        "\n",
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 4085\n",
            "Test: 637\n",
            "Re-starting from epoch 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSqldO8mKi5J"
      },
      "source": [
        "# evaluate model on test dataset\n",
        "#test_mAP = evaluate_model(test_set, model, cfg)\n",
        "#print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoUu9BV0dc-V"
      },
      "source": [
        "#########################################\n",
        "#Draw results on an images from dataset\n",
        "#########################################\n",
        "\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "    # load image and mask\n",
        "    for i in range(n_images):\n",
        "        # load the image and mask\n",
        "        image = dataset.load_image(i)\n",
        "        mask, _ = dataset.load_mask(i)\n",
        "        # convert pixel values (e.g. center)\n",
        "        scaled_image = mold_image(image, cfg)\n",
        "        # convert image into one sample\n",
        "        sample = expand_dims(scaled_image, 0)\n",
        "        # make prediction\n",
        "        yhat = model.detect(sample, verbose=0)[0]\n",
        "        # define subplot\n",
        "        pyplot.subplot(n_images, 2, i*2+1)\n",
        "        # plot raw pixel data\n",
        "        pyplot.imshow(image)\n",
        "        pyplot.title('Actual')\n",
        "        # plot masks\n",
        "        for j in range(mask.shape[2]):\n",
        "            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "        # get the context for drawing boxes\n",
        "        pyplot.subplot(n_images, 2, i*2+2)\n",
        "        # plot raw pixel data\n",
        "        pyplot.imshow(image)\n",
        "        pyplot.title('Predicted')\n",
        "        ax = pyplot.gca()\n",
        "        # plot each box\n",
        "        for k in range(len(yhat['rois'])):\n",
        "            box = yhat['rois'][k]\n",
        "            #for box in yhat['rois']:\n",
        "            # get coordinates\n",
        "            y1, x1, y2, x2 = box\n",
        "            # calculate width and height of the box\n",
        "            width, height = x2 - x1, y2 - y1\n",
        "            # create the shape\n",
        "            colorshape='black'\n",
        "            if yhat['class_ids'][k] == 1:\n",
        "                colorshape = 'red'\n",
        "            if yhat['class_ids'][k] == 2:\n",
        "                colorshape = 'blue'\t    \n",
        "            rect = Rectangle((x1, y1), width, height, fill=False, color=colorshape)\n",
        "            # draw the box\n",
        "            ax.add_patch(rect)\n",
        "    # show the figure\n",
        "    pyplot.show()\n",
        "\n",
        "\n",
        "# plot predictions for train dataset\n",
        "plot_actual_vs_predicted(train_set, model, cfg)\n",
        "\n",
        "# plot predictions for test dataset\n",
        "plot_actual_vs_predicted(test_set, model, cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LGcvnHaOoNR"
      },
      "source": [
        "### Comprobar rendimiento con 150 imagenes del conjunto de la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFJrGd_Yyu18"
      },
      "source": [
        "###############################################################\n",
        "#Draw results on an image from dataset (display mask and type)\n",
        "###############################################################\n",
        "imagelist = []\n",
        "\n",
        "for i in range(150):\n",
        "  image_id = i\n",
        "  original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_val, cfg, \n",
        "                            image_id, use_mini_mask=False)\n",
        "\n",
        "  # make prediction\n",
        "  yhat = model.detect([original_image], verbose=1)[0]\n",
        "  imagelist.append(yhat)\n",
        "  visualize.display_instances(original_image, yhat['rois'], yhat['masks'], yhat['class_ids'], \n",
        "                            dataset_val.class_names, yhat['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS65dd-5vsTI"
      },
      "source": [
        "for i in range(1):\n",
        "  image_id = id_image(\"\")\n",
        "  original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_train, cfg, \n",
        "                            image_id, use_mini_mask=False)\n",
        "\n",
        "  # make prediction\n",
        "  yhat = model.detect([original_image], verbose=1)[0]\n",
        "\n",
        "  visualize.display_instances(original_image, yhat['rois'], yhat['masks'], yhat['class_ids'], \n",
        "                            dataset_train.class_names, yhat['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcurUO5qLUie"
      },
      "source": [
        "###############################################################\n",
        "#Draw results on an image from dataset (display mask and type)\n",
        "###############################################################\n",
        "for i in range(20):\n",
        "  image_id = i\n",
        "  original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_train, cfg, \n",
        "                            image_id, use_mini_mask=False)\n",
        "\n",
        "  # make prediction\n",
        "  yhat = model.detect([original_image], verbose=1)[0]\n",
        "\n",
        "  visualize.display_instances(original_image, yhat['rois'], yhat['masks'], yhat['class_ids'], \n",
        "                            dataset_train.class_names, yhat['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKL2ZXW67R1w"
      },
      "source": [
        "###############################################################\n",
        "#Draw results on an image from dataset (display mask and type)\n",
        "###############################################################\n",
        "for i in range(20):\n",
        "  dir = \"img (\"+str(i+613)+\").jpg\"\n",
        "  print(dir)\n",
        "  image_id = id_image_test(dir)\n",
        "  print(image_id)\n",
        "  original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(test_set, cfg, \n",
        "                            image_id, use_mini_mask=False)\n",
        "\n",
        "  # make prediction\n",
        "  yhat = model.detect([original_image], verbose=1)[0]\n",
        "\n",
        "  visualize.display_instances(original_image, yhat['rois'], yhat['masks'], yhat['class_ids'], \n",
        "                            test_set.class_names, yhat['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pCM8BBsAXMs",
        "outputId": "3989eef5-f828-4f87-d230-6d8172cb2075"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3wlDSZYHpF1"
      },
      "source": [
        "model_save_name = 'classifierMaskRcnnNewL.pt'\n",
        "path = F\"/content/drive/My Drive/{model_save_name}\" \n",
        "model.keras_model.save_weights(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBnCyqZeOhjD"
      },
      "source": [
        "### Probar imagenes propias con los pesos entrenados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvzNjpwwi1AN"
      },
      "source": [
        "#########################################\n",
        "#Draw results on an image (display mask)\n",
        "#########################################\n",
        "\n",
        "import skimage.color\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "\n",
        "#adapted from class Dataset load_image (in utils.py)\n",
        "def load_image_prediction(img_path):\n",
        "    \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    image = skimage.io.imread(img_path)\n",
        "    # If grayscale. Convert to RGB for consistency.\n",
        "    if image.ndim != 3:\n",
        "        image = skimage.color.gray2rgb(image)\n",
        "    # If has an alpha channel, remove it for consistency\n",
        "    if image.shape[-1] == 4:\n",
        "        image = image[..., :3]\n",
        "    \n",
        "    return image\n",
        "        \n",
        "!wget https://e00-expansion.uecdn.es/assets/multimedia/imagenes/2017/02/05/14862885824518.jpg\n",
        "\n",
        "img_path='./14862885824518.jpg'\n",
        "\n",
        "image = load_image_prediction(img_path)  \n",
        "# convert pixel values (e.g. center)\n",
        "scaled_image = mold_image(image, cfg)\n",
        "# convert image into one sample\n",
        "sample = expand_dims(scaled_image, 0)\n",
        "# make prediction\n",
        "yhat = model.detect(sample, verbose=0)[0]\n",
        "\n",
        "#display masks and scores on image\n",
        "visualize.display_instances(image, yhat['rois'], yhat['masks'], yhat['class_ids'], \n",
        "                            dataset_val.class_names, yhat['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}