{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Algoritmos de mejora de la detección.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuMvkSRayZl1"
      },
      "source": [
        "Inicialización de los paquetes y librerias necesarios para al aplicación de los algoritmos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_tBZX1qyLAu"
      },
      "source": [
        "#Install needed packages (see requirements.txt in github repository)\n",
        "!pip install numpy\n",
        "!pip install \"scipy==1.4.1\"\n",
        "!pip install Pillow\n",
        "!pip install cython\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip uninstall keras-nightly\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.15.0\n",
        "!pip install keras==2.0.8\n",
        "!pip install opencv-python\n",
        "!pip uninstall h5py\n",
        "!pip install h5py==2.10.0\n",
        "!pip install imgaug\n",
        "\n",
        "#Download model\n",
        "!git clone https://github.com/nasca37/Mask_RCNN.git\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbMDzxVGyhcx"
      },
      "source": [
        "%cd Mask_RCNN/\n",
        "\n",
        "#Download pre-trained weights \n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvgsDCRrym7y"
      },
      "source": [
        "%cd Mask_RCNN/\n",
        "DATASET = 0\n",
        "\n",
        "!wget https://www.dropbox.com/s/660s0vgyk83aek9/Img.zip\n",
        "!wget https://www.dropbox.com/s/52ux32n0yu5xaq0/ImgTrain.zip\n",
        "!wget https://www.dropbox.com/s/yes1a53053zi6pv/Maskjson.zip\n",
        "!wget https://www.dropbox.com/s/brkhhd31cytt7z3/MaskTrainjson.zip\n",
        "!wget https://www.dropbox.com/s/f7hfuw0o36t0lox/ftc.py\n",
        "\n",
        "\n",
        "!unzip Img.zip\n",
        "!unzip Maskjson.zip \n",
        "!unzip ImgTrain.zip\n",
        "!unzip MaskTrainjson.zip  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cERjY-ugdha"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6gfI4Duyn_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00980dbe-01a2-46a0-e35b-0848f80482dc"
      },
      "source": [
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from matplotlib import pyplot\n",
        "from csv import reader\n",
        "import json\n",
        "import numpy as np\n",
        "import ntpath\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from ftc import FTCsegmentation\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"./\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.utils import extract_bboxes\n",
        "\n",
        "\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "DATASET_DIR_TEST=os.path.join(ROOT_DIR, \"Img\")\n",
        "#DATASET_MASK_TEST=os.path.join(ROOT_DIR, \"Mask\")\n",
        "DATASET_MASK_TEST=os.path.join(ROOT_DIR, \"Maskjson\")\n",
        "DATASET_DIR_TRAIN=os.path.join(ROOT_DIR, \"ImgTrain\")\n",
        "#DATASET_MASK_TRAIN=os.path.join(ROOT_DIR, \"MaskTrain\")\n",
        "DATASET_MASK_TRAIN=os.path.join(ROOT_DIR, \"MaskTrainjson\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yr04Suszj22"
      },
      "source": [
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "\n",
        "class ShadowsConfig(Config):\n",
        "    \"\"\"Configuration for training on the   dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"Shadows\"\n",
        "    \n",
        "    # A GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "#    IMAGES_PER_GPU = 2\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + shadow\n",
        "    \n",
        "    # Number of training steps per epoch\n",
        "    #STEPS_PER_EPOCH = 200\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "    MINI_MASK_SHAPE = (128, 128)\n",
        "    MASK_SHAPE = [56,56]\n",
        "    LOSS_WEIGHTS = {\n",
        "      \"rpn_class_loss\":1.,\n",
        "      \"rpn_bbox_loss\": 1.,\n",
        "      \"mrcnn_class_loss\": 1.,\n",
        "      \"mrcnn_bbox_loss\": 1.,\n",
        "      \"mrcnn_mask_loss\": 1.\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYRmFcTAzmLm"
      },
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import skimage\n",
        "import re\n",
        "class ShadowDataset(Dataset):\n",
        "\n",
        "    def load_shadow(self, isTrain = True):\n",
        "        \"\"\"Load a subset of the nuclei dataset.\n",
        "\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. Either the name of the sub-directory,\n",
        "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
        "                * train: stage1_train excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset nucleus, and the class nucleus\n",
        "        self.add_class(\"shadow\", 1, \"shadow\")\n",
        "        if isTrain:\n",
        "          dataset_dir = DATASET_DIR_TRAIN\n",
        "        else:\n",
        "          dataset_dir = DATASET_DIR_TEST\n",
        "\n",
        "        # Get image ids from directory names\n",
        "        image_ids = next(os.walk(dataset_dir))[2]\n",
        "        p = 0.99\n",
        "\n",
        "        n=len(image_ids)\n",
        "        all_indices=np.arange(n)\n",
        "        ntrain=int(p*n)\n",
        "        np.random.seed(100) #run this line before np.random.choice to choose always the same sequence of values\n",
        "        fimage_ids=np.random.choice(n, ntrain, replace=False)\n",
        "        \n",
        "        # Add images\n",
        "        for image_id in fimage_ids:\n",
        "            self.add_image(\n",
        "                \"shadow\",\n",
        "                image_id=image_ids[image_id],\n",
        "                path=os.path.join(dataset_dir, image_ids[image_id]))\n",
        "\n",
        "        \n",
        "\n",
        "    def load_mask(self, image_id,isTrain = True):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        id = re.findall(r'\\d+', info['id'])[0]\n",
        "        # Get mask directory from image path\n",
        "        if isTrain == False:\n",
        "          #mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"Mask/mask ({}).json\".format(id))\n",
        "          mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"Maskjson/mask ({}).json\".format(id))\n",
        "        else:\n",
        "          #mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"MaskTrain/mask ({}).json\".format(id))\n",
        "          mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"MaskTrainjson/mask ({}).json\".format(id))\n",
        "          \n",
        "        # Read mask info from .json file\n",
        "        datashadows = json.load(open(mask_dir))\n",
        "        # create one array for all masks, each on a different channel\n",
        "        mask = np.zeros([datashadows[\"height\"], datashadows[\"width\"], len(datashadows[\"regions\"])],\n",
        "                        dtype=np.uint8)\n",
        "             \n",
        "        for i, p in enumerate(datashadows[\"regions\"]):\n",
        "            mask[p['y'], p['x'], i] = 1\n",
        "        \n",
        "        \n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID, we return an array of ones\n",
        "        \n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"shadow\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsIA4QfMQlL8"
      },
      "source": [
        "Es importante que en esta casilla se use la ruta que contiene los pesos entrenados. Como GitHub no permite hacer uso de ficheros con tamaños superiores a los 100Mb se deberá bajar de la url proporcionada en el Readme del repositorio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6YMo6r50sEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df19e256-fdf3-41da-b98c-fdc0caba5206"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DIR = \"/content/drive/MyDrive/classifierMaskRcnnLAll2.pt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehgqmDLd1C-P"
      },
      "source": [
        "###################################\n",
        "#Evaluation of the trained model\n",
        "###################################\n",
        "\n",
        "# evaluate the mask rcnn model on the facesFDDB dataset\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "import math\n",
        "\n",
        "arrayConResultados = list()\n",
        "\n",
        "# define the prediction configuration\n",
        "class PredictionConfig(Config):\n",
        "    # define the name of the configuration\n",
        "    NAME = \"shadow\"\n",
        "    # number of classes (background + eye + mouth)\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    # simplify GPU config\n",
        "    GPU_COUNT = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0.85\n",
        "    IMAGES_PER_GPU = 1\n",
        "    MINI_MASK_SHAPE = (128, 128)\n",
        "    MASK_SHAPE = [56,56]\n",
        "\n",
        "# calculate the mAP for a model on a given dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "  \n",
        "\tnumber = 0\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tif not math.isnan(AP):\n",
        "\t\t    APs.append(AP)\n",
        "\t\t    arrayConResultados.append((image_id,AP))\n",
        "        \n",
        "\t\tnumber = number + 1\n",
        "\t\tif (number % 100) == 0:\n",
        "\t\t    print(\"the number is {}\".format(number))\n",
        "      \n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP\n",
        "\n",
        "# load the train dataset\n",
        "train_set = ShadowDataset()\n",
        "train_set.load_shadow(isTrain=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# load the test dataset\n",
        "test_set = ShadowDataset()\n",
        "test_set.load_shadow(isTrain=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "\n",
        "# create config\n",
        "cfg = PredictionConfig()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir=DEFAULT_LOGS_DIR, config=cfg)\n",
        "# load model weights\n",
        "model.load_weights(DIR, by_name=True)\n",
        "\n",
        "# evaluate model on training dataset\n",
        "#train_mAP = evaluate_model(train_set, model, cfg)\n",
        "#print(\"Train mAP: %.3f\" % train_mAP)\n",
        "#print(arrayConResultados)\n",
        "\n",
        "# evaluate model on test dataset\n",
        "#test_mAP = evaluate_model(test_set, model, cfg)\n",
        "#print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyL0uTE4_k3x"
      },
      "source": [
        "import cv2\n",
        "def display_instances2(image, boxes, masks, class_ids, class_names,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=True,\n",
        "                      colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "        auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = colors or visualize.random_colors(N)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    ax.set_ylim(height + 10, -10)\n",
        "    ax.set_xlim(-10, width + 10)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "    for i in range(N):\n",
        "        color = colors[i]\n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(p)\n",
        "\n",
        "        # Label\n",
        "        if not captions:\n",
        "            class_id = class_ids[i]\n",
        "            score = scores[i] if scores is not None else None\n",
        "            label = class_names[class_id]\n",
        "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
        "        else:\n",
        "            caption = captions[i]\n",
        "        ax.text(x1, y1 + 8, caption,\n",
        "                color='w', size=11, backgroundcolor=\"none\")\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = visualize.apply_mask(masked_image, mask, color)\n",
        "\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "            ax.add_patch(p)\n",
        "    ax.imshow(masked_image.astype(np.uint8))\n",
        "    if auto_show:      \n",
        "        plt.show()\n",
        "        plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6jzvP9nAM2G"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U1lFW8fdkcf"
      },
      "source": [
        "def id_image(name):\n",
        "  finalpath = \"/content/Mask_RCNN/ImgTrain/\" + name\n",
        "  for id in train_set.image_ids:\n",
        "    path = train_set.image_reference(id)\n",
        "    if path == finalpath:\n",
        "      return id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L7G_uZePOEQ"
      },
      "source": [
        "## Comienzo del proceso de pruebas\n",
        "\n",
        "A partir de esta casilla empieza el proceso de pruebas de funcionamiento de los algoritmos de mejora.\n",
        "\n",
        "En la casila inferior se puede colocar el nombre de las imagenes que queremos hacer pruebas y de esta forma obtener sus mascaras mejoradas. Ademas se añade una imagen con una url exterior para hacer pruebas con imagenes de fuera de la base de datos. Para poder usar esas fotografias es necesario que la imagen tenga una resolución de 1024 x 1024 para evitar problemas de compatibilidad con las predicciones del modelo. \n",
        "\n",
        "En la parte inferior del notebook se encuentra una función que realiza todos los algoritmos e intenta eliminar la sombra usando un metodo sencillo que no aporta muy buenos resultados. Este último proceso se deja en caso de querer ver como podría funcionar este porceso de eliminado de sombras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqt1zXnwVGwB"
      },
      "source": [
        "# 76 589 807 1723 997 2835\n",
        "from mrcnn import visualize\n",
        "path1 = \"img (2804).jpg\"\n",
        "path2 = \"img (2835).jpg\"\n",
        "path3 = \"img (76).jpg\"\n",
        "image_id1 = id_image(path1)\n",
        "image_id2 = id_image(path2)\n",
        "image_id3 = id_image(path3)\n",
        "\n",
        "imagen1, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "  modellib.load_image_gt(train_set, cfg, \n",
        "                          image_id1, use_mini_mask=True)\n",
        "  \n",
        "imagen2, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "modellib.load_image_gt(train_set, cfg, \n",
        "                        image_id2, use_mini_mask=True)\n",
        "\n",
        "imagen3, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "modellib.load_image_gt(train_set, cfg, \n",
        "                        image_id3, use_mini_mask=True)\n",
        "\n",
        "resultados1 = model.detect([imagen1],verbose=0)[0]\n",
        "resultados2 = model.detect([imagen2],verbose=0)[0]\n",
        "resultados3 = model.detect([imagen3],verbose=0)[0]\n",
        "\n",
        "def load_image_prediction(img_path):\n",
        "    \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    image = skimage.io.imread(img_path)\n",
        "    # If grayscale. Convert to RGB for consistency.\n",
        "    if image.ndim != 3:\n",
        "        image = skimage.color.gray2rgb(image)\n",
        "    # If has an alpha channel, remove it for consistency\n",
        "    if image.shape[-1] == 4:\n",
        "        image = image[..., :3]\n",
        "    return image\n",
        "\n",
        "img = !wget -O limpiar.jpg https://drive.google.com/uc?id=1be36EhGZJPDH8zJvnbbRgA8Jd7FWTdHw&export=download\n",
        "img_path='./limpiar.jpg'\n",
        "imagen4 = load_image_prediction(img_path)  \n",
        "# convert pixel values (e.g. center)\n",
        "scaled_image = mold_image(imagen4, cfg)\n",
        "# convert image into one sample\n",
        "sample = expand_dims(scaled_image, 0)\n",
        "resultados4 = model.detect(sample,verbose=0)[0]\n",
        "\n",
        "visualize.display_instances(imagen4, resultados4['rois'], resultados4['masks'], resultados4['class_ids'], \n",
        "                            train_set.class_names, resultados4['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V2NQzS91DoI"
      },
      "source": [
        "## Algoritmos de mejora de la detección\n",
        "\n",
        "Dentro de este apartado se encuentra el aspecto principal de este notebook. Cada uno de los algoritmos contiene una colección de tres ejemplos. Este notebook hace uso de unos pesos que tengo en mi drive por tanto no se puede ejecutar sin mi cuenta. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhvh1jfG1zWy"
      },
      "source": [
        "### Algoritmo 1 \n",
        "Este primer algoritmo tiene como objetivo obtener una matriz bidimensional que contendrá que pixeles pertenecen a una sombra.\n",
        "\n",
        "- El input de este algoritmo es la lista de las máscaras de la imagen.\n",
        "\n",
        "- EL output es la matriz bidimensional que contiene un 1 en los pixeles que pertenezcan a una sombra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPrOYqTs0wr5"
      },
      "source": [
        "#Algoritmo 1\n",
        "import matplotlib.pyplot as plt\n",
        "from mrcnn.utils import resize_mask\n",
        "\n",
        "def obtenerMascaras(masks):\n",
        "  N = masks.shape[2]\n",
        "  \n",
        "  image = np.zeros((1024,1024))\n",
        "  for i in range(N):\n",
        "\n",
        "    image = image + masks[:, :, i].astype(int)\n",
        "\n",
        "  for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "      if(image[i][j] > 0):\n",
        "        image[i][j] = 1\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fyD01rX3SCN"
      },
      "source": [
        "### Pruebas del funcionamiento del algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDc6PGhh5TUG"
      },
      "source": [
        "from matplotlib.pyplot import figure\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (25,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DK_JQvpEzjM"
      },
      "source": [
        "def overlay_image(image,mask):\n",
        "  mask_image = skimage.color.label2rgb(mask,bg_color=(0,0,0),colors=[(0,0,0),(1,0,0)])\n",
        "  plt.imshow(image,cmap='hsv',interpolation='none')\n",
        "  plt.imshow(mask_image,cmap='gray',interpolation='none',alpha=0.25)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5IIsSzx3REC"
      },
      "source": [
        "mascaras1 = obtenerMascaras(resultados1['masks'])\n",
        "mascaras2 = obtenerMascaras(resultados2['masks'])\n",
        "mascaras3 = obtenerMascaras(resultados3['masks'])\n",
        "mascaras4 = obtenerMascaras(resultados4['masks'])\n",
        "#Muestra gráfica\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(mascaras1)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagen1)\n",
        "plt.show()\n",
        "overlay_image(imagen1,mascaras1)\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(mascaras2)\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(imagen2)\n",
        "plt.show()\n",
        "overlay_image(imagen2,mascaras2)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(imagen2)\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(mascaras3)\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(imagen3)\n",
        "plt.show()\n",
        "overlay_image(imagen3,mascaras3)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(imagen3)\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(mascaras4)\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(imagen4)\n",
        "plt.show()\n",
        "overlay_image(imagen4,mascaras4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLZ9Vq153SsY"
      },
      "source": [
        "### Algoritmo 2\n",
        "Algoritmo que recibe el resultado del algoritmo anterior y tiene como objetivo obtener una lista con las componentes conexas. Es decir una lista con los pixeles que pertenecen a una sombra.\n",
        "\n",
        "- Input: Matriz bidimensional que contiene los pixeles que son y no son sombras.\n",
        "\n",
        "- Output: Lista de componentes conexas\n",
        "\n",
        "Para resolver este problema se usa la libreria de scipy la cual contiene operaciones para trabajar con elementos de visión por computacion. Esta libreria devuelve una imagen donde cada cc esta etiquetada. De esta forma con un bucle cuadratico obtenemos en función de este indice cada una de las cc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tuR6S8I0xpK"
      },
      "source": [
        "#Algoritmo 2\n",
        "from scipy import ndimage\n",
        "\n",
        "def obtenerComponentesConexas(image):\n",
        "  labels,nb = ndimage.label(image)\n",
        "\n",
        "  listaComponentes = []\n",
        "  for k in range(nb):\n",
        "    cc = []\n",
        "    for i in range(labels.shape[0]):\n",
        "      for j in range(labels.shape[1]):\n",
        "        if labels[i][j] == (k+1):\n",
        "          cc.append((i,j))\n",
        "    listaComponentes.append(cc)\n",
        "\n",
        "  return listaComponentes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDjY1RQ3JRcM"
      },
      "source": [
        "def printCC(image,cc):\n",
        "  mascara = np.zeros((image.shape[0],image.shape[1]))\n",
        "  if cc != None:\n",
        "    for i in range(len(cc)):\n",
        "      x = cc[i][1]\n",
        "      y = cc[i][0]\n",
        "      mascara[y,x] = 1\n",
        "\n",
        "    overlay_image(image,mascara)\n",
        "\n",
        "def printMask(image,cc):\n",
        "  mascara = np.zeros((image.shape[0],image.shape[1]))\n",
        "  if cc != None:\n",
        "    for i in range(len(cc)):\n",
        "      x = cc[i][1]\n",
        "      y = cc[i][0]\n",
        "      mascara[y,x] = 1\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(mascara, cmap='gray',  interpolation='nearest')\n",
        "    plt.savefig('mask.png')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygo18_bA4ccy"
      },
      "source": [
        "### Algoritmo 3\n",
        "Este algoritmo debe generar un histograma de la intensidad de la componente conexa que recibe.\n",
        "\n",
        "- Input: Componente conexa.\n",
        "- Output: Histograma con las intensidades.\n",
        "\n",
        "Para poder calcular esta itesidad se pasa la imagen que recibimos a una imagen en escala de grises. Para obtener esto se usa una función auxiliar que devuelve una matriz bidemensional de forma que se usa la formula de la intensidad. Esta formula esta ajustada a la escala RGB por tanto se deberia ajustar en función al tipo de distribución de color de la imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVo2MreZ0xso"
      },
      "source": [
        "#Algoritmo 3\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.21, 0.72, 0.07])\n",
        "\n",
        "def histograma(original_image,componenteConexa,show=True):\n",
        "  histograma = []\n",
        "  histograma = np.zeros(256)\n",
        "  intensity =  0\n",
        "  bins = np.arange(256)\n",
        "  gray_image = rgb2gray(original_image)\n",
        "  for i in range(len(componenteConexa)):\n",
        "    x = componenteConexa[i][0]\n",
        "    y = componenteConexa[i][1]\n",
        "    intensity = gray_image[x][y]\n",
        "    intensity = math.floor(intensity)\n",
        "\n",
        "    histograma[intensity] = histograma[intensity] + 1\n",
        "\n",
        "  if show:\n",
        "    plt.bar(bins,histograma,align=\"center\")\n",
        "    plt.show()\n",
        "  \n",
        "  return histograma\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpBtbGeoyWjp"
      },
      "source": [
        "### Algoritmo 4\n",
        "Este algoritmo debe aplicar el algoritmo de otsu para obtener un valor threshold que permita separar las intensidades que pertenezcan a la sombra y los valores que pertenezcan a la luz.\n",
        "\n",
        "- Input: Histograma.\n",
        "- Output: Threshold.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BFk5gyl0xt1"
      },
      "source": [
        "#Algoritmo 4\n",
        "\n",
        "def obtain_threshold(histograma):\n",
        "  hist_norm = np.ravel(histograma)/np.max(histograma)\n",
        "  Q = np.cumsum(hist_norm)\n",
        "\n",
        "  bins = np.arange(256)\n",
        "\n",
        "  fn_min = np.inf\n",
        "  thresh = -1\n",
        "\n",
        "  for i in range(0,254):\n",
        "      p1,p2 = np.hsplit(hist_norm,[i]) # probabilities\n",
        "      q1,q2 = Q[i],Q[254]-Q[i] # cum sum of classes\n",
        "      b1,b2 = np.hsplit(bins,[i]) # weights\n",
        "\n",
        "      # finding means and variances\n",
        "      m1,m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2\n",
        "      v1,v2 = np.sum(((b1-m1)**2)*p1)/q1,np.sum(((b2-m2)**2)*p2)/q2\n",
        "\n",
        "      # calculates the minimization function\n",
        "      fn = v1*q1 + v2*q2\n",
        "      if fn < fn_min:\n",
        "          fn_min = fn\n",
        "          thresh = i\n",
        "\n",
        "  return thresh\n",
        "\n",
        "import statistics\n",
        "\n",
        "def shadow_addition_treshold(hist):\n",
        "  intensidades = []\n",
        "  for i in range(len(hist)):\n",
        "    for j in range(int(hist[i])):\n",
        "      intensidades.append(i)\n",
        "  \n",
        "  media = np.mean(intensidades)\n",
        "  stv = 0\n",
        "  if len(intensidades) > 1:\n",
        "    stv = statistics.stdev(intensidades)\n",
        "    \n",
        "  return (media + stv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1KaqZu0GdKQ"
      },
      "source": [
        "def algoritmos4_2(h):\n",
        "  separators = FTCsegmentation(h, 1, 0, 2)  #1, 0, y 2 son parametros fijos del algoritmo\n",
        "  threshold = -1\n",
        "  if len(separators) == 3:\n",
        "      threshold = 1\n",
        "      \n",
        "  else:\n",
        "      print(\"El histograma es unimodal\")\n",
        "\n",
        "  return threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yns3TxOKIuql"
      },
      "source": [
        "def pruebaHisto(imagen,mascaras):\n",
        "\n",
        "  lista_componentes_conexas_imagen =  obtenerComponentesConexas(mascaras)\n",
        "  thresh_values = []\n",
        "  for i in range(len(lista_componentes_conexas_imagen)):\n",
        "    print(\"Histograma de la componente conexa {}\".format(i))\n",
        "    histo = histograma(imagen,lista_componentes_conexas_imagen[i])\n",
        "    printCC(imagen,lista_componentes_conexas_imagen[i])\n",
        "    thresh = obtain_threshold(histo)\n",
        "    thresh2 = algoritmos4_2(histo)\n",
        "    \n",
        "    shadow_addition = shadow_addition_treshold(histo)\n",
        "    print(\"El valor de separación de esta componente conexa es: {}\".format(thresh))\n",
        "    thresh_values.append((thresh,shadow_addition,thresh2))\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    \n",
        "\n",
        "\n",
        "  return thresh_values\n",
        "\n",
        "t1 = pruebaHisto(imagen1,mascaras1)\n",
        "t2 = pruebaHisto(imagen2,mascaras2)\n",
        "t3 = pruebaHisto(imagen3,mascaras3)\n",
        "t4 = pruebaHisto(imagen4,mascaras4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDmauwC7ynTb"
      },
      "source": [
        "### Algoritmo 5\n",
        "Este algoritmo debe aplicar el valor threshold que hemos obtenido anteriormente para eliminar de la componente conexa los valores que esten por debajo del valor.\n",
        "- Input: Componente conexa, imagen original y el valor de separación.\n",
        "- Output: Componente conexa con los pixeles con intensidades por debajo del valor de separación.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKI2OnVc0xyH"
      },
      "source": [
        "#Algoritmo 5\n",
        "\n",
        "def componenteConexaLimpiaThreshold(cc,image,thresh):\n",
        "  if thresh == -1:\n",
        "    return cc\n",
        "    \n",
        "  gray_image = rgb2gray(image)\n",
        "  aux = []\n",
        "  for k in range(len(cc)):\n",
        "    x = cc[k][1]\n",
        "    y = cc[k][0]\n",
        "    intensity = gray_image[y][x]\n",
        "    intensity = math.floor(intensity)\n",
        "    if intensity <= thresh:\n",
        "      aux.append(cc[k])\n",
        "\n",
        "  return aux\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jw_-xCjMC7q"
      },
      "source": [
        "def pruebaLimpieza(imagen,mascaras,valores):\n",
        "\n",
        "  lista_componentes_conexas_imagen =  obtenerComponentesConexas(mascaras)\n",
        "  cc_limpias = []\n",
        "  for i in range(len(lista_componentes_conexas_imagen)):\n",
        "    if valores[i][2] != -1:\n",
        "      ccLimpia = componenteConexaLimpiaThreshold(lista_componentes_conexas_imagen[i],imagen,valores[i][0])\n",
        "    else:\n",
        "      #ccLimpia = lista_componentes_conexas_imagen[i]\n",
        "      ccLimpia = componenteConexaLimpiaThreshold(lista_componentes_conexas_imagen[i],imagen,valores[i][0])\n",
        "    \n",
        "    print(\"Comparacion mascaras de la cc {}\".format(i))\n",
        "    print(\"El valor threshold es: {}\".format(valores[i][0]))\n",
        "    printCC(imagen,lista_componentes_conexas_imagen[i])\n",
        "    printCC(imagen,ccLimpia)\n",
        "    cc_limpias.append(ccLimpia)\n",
        "    print(\"---------------------------------------------------------\")\n",
        "  \n",
        "  return cc_limpias\n",
        "\n",
        "cc1L = pruebaLimpieza(imagen1,mascaras1,t1)\n",
        "cc2L = pruebaLimpieza(imagen2,mascaras2,t2)\n",
        "cc3L = pruebaLimpieza(imagen3,mascaras3,t3)\n",
        "cc4L = pruebaLimpieza(imagen4,mascaras4,t4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPxF3rr3y8bN"
      },
      "source": [
        "### Algoritmo 6\n",
        "Este algoritmo debe aplicar el valor threshold que hemos obtenido anteriormente y la componenete conexa limpia para añadir a la componente los pixeles cercanos que tengan la intensidad por debajo del threshold.\n",
        "- Input: Componente conexa limpia , imagen original y el valor de separación.\n",
        "- Output: Componente conexa con los nuevos pixeles con intensidades por debajo del valor de separación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu9eRBLY0xzw"
      },
      "source": [
        "#Algoritmo 6\n",
        "\n",
        "def mejorarSombra(original_image,cc,tresh,mask):\n",
        "  if tresh == -1:\n",
        "    return cc\n",
        "\n",
        "  pila_pixeles = cc.copy()\n",
        "  gray_image = rgb2gray(original_image)\n",
        "  threshold = tresh\n",
        "  while len(pila_pixeles) != 0:\n",
        "    \n",
        "    \n",
        "    punto_aux = pila_pixeles.pop()\n",
        "    x = punto_aux[1]\n",
        "    y = punto_aux[0]\n",
        "    \n",
        "    if x + 1 < gray_image.shape[1]:\n",
        "      if gray_image[y][x+1] < threshold and gray_image[y][x+1] > 0 and mask[y][x+1] != 1:\n",
        "        pila_pixeles.append((y,x+1))\n",
        "        cc.append((y,x+1))\n",
        "        mask[y][x+1] = 1\n",
        "    if x - 1 > 0:\n",
        "      if gray_image[y][x-1] < threshold and gray_image[y][x-1] > 0 and mask[y][x-1] != 1:\n",
        "        pila_pixeles.append((y,x-1))\n",
        "        cc.append((y,x-1))\n",
        "        mask[y][x-1] = 1\n",
        "\n",
        "    if y + 1 < gray_image.shape[0]:\n",
        "      if gray_image[y+1][x] < threshold and gray_image[y+1][x] > 0 and mask[y+1][x] != 1:\n",
        "        pila_pixeles.append((y+1,x))\n",
        "        cc.append((y+1,x))\n",
        "        mask[y+1][x] = 1\n",
        "        \n",
        "    if y - 1 > 0:\n",
        "      if gray_image[y-1][x] < threshold and gray_image[y-1][x] > 0 and mask[y-1][x] != 1 :\n",
        "        pila_pixeles.append((y-1,x))\n",
        "        cc.append((y-1,x))\n",
        "        mask[y-1][x] = 1\n",
        "\n",
        "\n",
        "\n",
        "  return cc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tet7PX7zeAR2"
      },
      "source": [
        "### Algoritmo 7\n",
        "Este algoritmo final debe de generar la matriz bidimensional que contiene la detección de las sombras mejoradas.\n",
        "\n",
        "- Input: Lista de componentes conexas limpias y ampliadas.\n",
        "\n",
        "- Output: Matriz bidimensional de la máscara final.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itkhsUjDJeGQ"
      },
      "source": [
        "#Algotimo auxiliar\n",
        "def generarMask(lista_cc):\n",
        "  mask = np.zeros((1024,1024))\n",
        "  for cc in lista_cc:\n",
        "    for i in range(len(cc)):\n",
        "\n",
        "      x = cc[i][1]\n",
        "      y = cc[i][0]\n",
        "      mask[y][x] = 1\n",
        "\n",
        "  return mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EijzuEI0x33"
      },
      "source": [
        "def pruebaMejora(imagen,ccLimpias,valores):\n",
        "\n",
        "\n",
        "  cc_mejoradas = []\n",
        "  mask = generarMask(ccLimpias)\n",
        "  plt.imshow(mask)\n",
        "  plt.show()\n",
        "  for i in range(len(ccLimpias)):\n",
        "    printCC(imagen,ccLimpias[i])\n",
        "    ccMejorada = mejorarSombra(imagen,ccLimpias[i],valores[i][1],mask)\n",
        "    print(\"Comparacion mascaras de la cc {}\".format(i))\n",
        "    print(\"El valor threshold es: {}\".format(valores[i][1]))\n",
        "   \n",
        "    printCC(imagen,ccMejorada)\n",
        "    printMask(imagen,ccMejorada)\n",
        "    cc_mejoradas.append(ccMejorada)\n",
        "    print(\"---------------------------------------------------------\")\n",
        "  \n",
        "  return cc_mejoradas\n",
        "\n",
        "cc1M = pruebaMejora(imagen1,cc1L,t1)\n",
        "cc2M = pruebaMejora(imagen2,cc2L,t2)\n",
        "cc3M = pruebaMejora(imagen3,cc3L,t3)\n",
        "cc4M = pruebaMejora(imagen4,cc4L,t4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei96IiGc8SMv"
      },
      "source": [
        "def showMask(maskList,image):\n",
        "  mask = generarMask(maskList)\n",
        "  \n",
        "  overlay_image(image,mask)\n",
        "\n",
        "\n",
        "showMask(cc4M,imagen4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibSWh1mFzaKe"
      },
      "source": [
        "A partir de esta sección se encuentran los dos algoritmos que se han estado probando para limpiar la sombra, no consideramos que sean buenos pero son representativos de aplicaciones para futura investigación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqjPuDJylxww"
      },
      "source": [
        "#Algoritmo 8\n",
        "def insideR(mask,y,x,r=10):\n",
        "  \n",
        "  for i in range(y,y+r):\n",
        "    for j in range(x,x+r):\n",
        "      if i < 1024 and j < 1024:\n",
        "        if mask[i][j] == 1:\n",
        "          return True\n",
        "  \n",
        "  return False\n",
        "\n",
        "\n",
        "def eliminarCC(cc,original_image,r=10):\n",
        "  plt.imshow(original_image)\n",
        "  plt.show()\n",
        "  grey_image = rgb2gray(original_image)\n",
        "  plt.imshow(grey_image)\n",
        "  plt.show()\n",
        "  itsDark = []\n",
        "  itsLight = []\n",
        "  #mascara = np.zeros((original_image.shape[0],original_image.shape[1]))\n",
        "  lumineP = []\n",
        "  for i in range(len(cc)):\n",
        "    x = cc[i][1]\n",
        "    y = cc[i][0]\n",
        "   # mascara[y][x] = 1\n",
        "    itsDark.append(grey_image[y][x])\n",
        "    for k in range(1,r):\n",
        "      x_1 = x + k\n",
        "      y_1 = y + k\n",
        "      if y_1 < 1024 and x_1 < 1024:\n",
        "        itsLight.append(grey_image[y_1][x_1])\n",
        "  \n",
        "  itsLight = list(set(itsLight) - set(itsDark))\n",
        "  Id = np.mean(itsDark)\n",
        "  Il = np.mean(itsLight)\n",
        "  ratio = Il/Id\n",
        "  print(ratio)\n",
        "  aux_image = original_image.copy()\n",
        "  print(len(cc))\n",
        "  pasos = 0\n",
        "  for g in range(len(cc)):\n",
        "    x = cc[g][1]\n",
        "    y = cc[g][0]\n",
        "    pixel_value = aux_image[y][x]\n",
        "    pixel_value= (pixel_value[0]*ratio,pixel_value[1]*ratio,pixel_value[2]*ratio)\n",
        "    aux_image[y][x] = pixel_value\n",
        "    pasos = pasos + 1\n",
        "\n",
        "  return aux_image\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "def eliminarCC2(cc,original_image,r=10):\n",
        "  #plt.imshow(original_image)\n",
        "  #plt.show()\n",
        "  grey_image = rgb2gray(original_image)\n",
        "  ycc = cv2.cvtColor(original_image,cv2.COLOR_RGB2YCrCb)\n",
        "  #plt.imshow(grey_image)\n",
        "  #plt.show()\n",
        "  itsDark = []\n",
        "  itsLight = []\n",
        "  #mascara = np.zeros((original_image.shape[0],original_image.shape[1]))\n",
        "  lumineP = []\n",
        "  for i in range(len(cc)):\n",
        "    x = cc[i][1]\n",
        "    y = cc[i][0]\n",
        "   # mascara[y][x] = 1\n",
        "    itsDark.append(ycc[y][x][0])\n",
        "    for k in range(1,r):\n",
        "      x_1 = x + k\n",
        "      y_1 = y + k\n",
        "      if y_1 < 1024 and x_1 < 1024:\n",
        "        itsLight.append(ycc[y_1][x_1][0])\n",
        "  \n",
        "  itsLight = list(set(itsLight) - set(itsDark))\n",
        "  Id = np.mean(itsDark)\n",
        "  Il = np.mean(itsLight)\n",
        "  diff = Il - Id\n",
        "  ratio = Il/Id\n",
        "  print(\"El ratio es {} y la diferencia es {}\".format(ratio,diff))\n",
        "  aux_image = ycc.copy()\n",
        "  \n",
        "  for g in range(len(cc)):\n",
        "    x = cc[g][1]\n",
        "    y = cc[g][0]\n",
        "    pixel_value = aux_image[y][x]\n",
        "    pixel_value= (pixel_value[0] + (diff) ,pixel_value[1],pixel_value[2] + ratio)\n",
        "    aux_image[y][x] = pixel_value\n",
        "    \n",
        "\n",
        "\n",
        "  imagen_final = cv2.cvtColor(aux_image,cv2.COLOR_YCR_CB2RGB)\n",
        "\n",
        "  return imagen_final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5q1uoyUlyHk"
      },
      "source": [
        "#Conjunto\n",
        "def mejorarImagen(id_image,mostrar = False):\n",
        " \n",
        "  original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(train_set, cfg, \n",
        "                            id_image, use_mini_mask=True)\n",
        "\n",
        "  # make prediction\n",
        "  yhat = model.detect([original_image], verbose=0)[0]\n",
        "\n",
        "\n",
        "  visualize.display_instances(original_image, yhat['rois'], yhat['masks'], yhat['class_ids'], \n",
        "                            train_set.class_names, yhat['scores'])\n",
        "\n",
        "  binary_mask = obtenerMascaras(yhat['masks'])\n",
        "  plt.imshow(original_image)\n",
        "  plt.show()\n",
        "  overlay_image(original_image,binary_mask)\n",
        "  lista_componentesConexas = obtenerComponentesConexas(binary_mask)\n",
        "  mask = generarMask(lista_componentesConexas)\n",
        "  copiaOriginal = original_image.copy()\n",
        "  mask_final=np.zeros((original_image.shape[0],original_image.shape[1]))\n",
        "\n",
        "  mask_clean = np.zeros((original_image.shape[0],original_image.shape[1]))\n",
        "  idx = 0\n",
        "  \n",
        "  for cc in lista_componentesConexas:\n",
        "    hist = histograma(copiaOriginal,cc,show=False)\n",
        "    threshold = obtain_threshold(hist)\n",
        "    corrector = shadow_addition_treshold(hist)\n",
        "    \n",
        "    cc_clean = componenteConexaLimpiaThreshold(cc,copiaOriginal,threshold)\n",
        "    #print(\"Componente limpia\")\n",
        "    #print(cc_clean)\n",
        "    if cc_clean != None:\n",
        "\n",
        "      for i in range(len(cc_clean)):\n",
        "        mask_clean[cc_clean[i][0]][cc_clean[i][1]] = 1\n",
        "\n",
        "    cc_final = mejorarSombra(copiaOriginal,cc_clean,corrector,mask)\n",
        "    #print(\"Componente final\")\n",
        "    #print(cc_final)\n",
        "    idx = idx + 1\n",
        "\n",
        "    \n",
        "    if cc_final != None:\n",
        "\n",
        "      for i in range(len(cc_final)):\n",
        "        mask_final[cc_final[i][0]][cc_final[i][1]] = 1\n",
        "      \n",
        "      temp_img = eliminarCC2(cc_final,original_image)\n",
        "      original_image = temp_img\n",
        "  \n",
        "  overlay_image(copiaOriginal,mask_clean)\n",
        "  \n",
        "  if mostrar:\n",
        "    overlay_image(copiaOriginal,mask_final)\n",
        "\n",
        "    plt.imshow(original_image)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tarp9QwgKJvQ"
      },
      "source": [
        "mejorarImagen(id_image(path1),True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CelsPvNDK4Hh"
      },
      "source": [
        "mejorarImagen(id_image(path2),True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azUGZt4yK5O1"
      },
      "source": [
        "mejorarImagen(id_image(path3),True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
